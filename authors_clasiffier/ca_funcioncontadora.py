# -*- coding: utf-8 -*-
"""CA_funcioncontadora.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s4pBorrFyynhLjFwADeeUD6bg2z5p1XP
"""

#total_palabras

# Total de palabras
#total_palabras.sum()

# Cargamos bibliotecas
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import nltk # Para procesamiento de texto
from nltk.stem import PorterStemmer
from nltk.stem import SnowballStemmer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# from sklearn.model_selection import train_test_split

nltk.download('punkt') # Remueve sugnos de puntuación
nltk.download('stopwords') # Remueve articulos

def contador_palabras(cancion, idioma = 'spanish'):
    cancion_cargada = open(cancion)
    lista_cancion = [verso for verso in cancion_cargada]
    formato_adecuado = '\n'.join(lista_cancion)
    palabras_cancion = word_tokenize(formato_adecuado.lower())
    raiz = SnowballStemmer(idioma)
    palabras_filtradas = [raiz.stem(palabra) for palabra in palabras_cancion if palabra not in set(stopwords.words(idioma)) and palabra.isalpha() == True]
    cantidad_palabra = pd.Series(palabras_filtradas).value_counts()
    return cantidad_palabra

def probabilidad_artista(artista):
    return contador_palabras(artista)/contador_palabras(artista).sum()

probabilidad_artista('AlejandroSanz.txt')

def particion(artista, lista_artistas):
    ae_1= "AlejandroSanz.txt"
    ae_2= "Love of lesbian.txt"
    ae_3= "jose_jose.txt"
    ae_4= "luis_miguel.txt"
    ae_5= "melendi.txt"
    ae_6= "miguel_bose.txt"
    autores = [ae_1, ae_2, ae_3, ae_4, ae_5, ae_6]
    prob_token= pd.DataFrame(contador_palabras(artista)-contador_palabras(artista))
    prob_token['Total']= prob_token
    for autor in autores:
        prob_token[autor] = (contador_palabras(autor)/contador_palabras(autor).sum())
    prob_token.fillna(0, inplace=True)
    prob_token['Total']= prob_token[ae_1] + prob_token[ae_2]+ prob_token[ae_3]+ prob_token[ae_4]+ prob_token[ae_5]+prob_token[ae_6]
    return prob_token['Total']

ae_1= "AlejandroSanz.txt"
ae_2= "Love of lesbian.txt"
ae_3= "jose_jose"
ae_4= "luis_miguel"
ae_5= "melendi.txt"
ae_6= "miguel_bose"
autores_español = [ae_1, ae_2, ae_3, ae_4, ae_5, ae_6]

# Para unir todos los archivos de texto
with open('autores_totales.txt', 'w') as new_file: #'w' inidica que se sobreescribirá en el texto
    for autor in autores_español: #toma cada archivo de texto
        with open(autor) as a: #abre cada archivo de texto
            for line in a: #va pasando cada linea de cada texto al texto nuevo
                new_file.write(line)
            new_file.write("\n")

# Archivo donde estan guardadas todas las canciones
total_palabras = contador_palabras('autores_totales.txt')

ola = particion('autores_totales.txt', autores_español)
ola

ola['desvan']

def probabilidad_final(artista, palabra):
    return probabilidad_artista(artista, palabra)/particion(artista, palabra)

probabilidad_final("AlejandroSanz.txt", 'si')

#def data_frame(artista):
#    data_frame = pd.DataFrame(contador_palabras(artista))
#    for palabra in contador_palabras(artista):
#        data_frame['Probabilidad'] = probabilidad_final(artista, palabra)
#    return data_frame

contador_palabras('Amiga_Mia.txt')

prueba = 0
for palabra in contador_palabras('Amiga_Mia.txt'):
    prueba = prueba + probabilidad_final('Amiga_Mia.txt', palabra)

